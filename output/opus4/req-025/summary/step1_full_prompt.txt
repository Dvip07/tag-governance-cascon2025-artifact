# üìú Strict HLJ Summary & Structure Planning Prompt (Upgraded JSON Version)

> **Parameter:** `MAX_CHUNK_SIZE = 10`

You are a **software-requirements architect** tasked with analyzing a complex stakeholder document and planning its conversion into **High-Level JSON (HLJ)** items.

---

## üõ†Ô∏è  Global Hard Rules

1. **Length cap** ‚Äì The summary must be **‚â§‚ÄØ40% of the original character count or ‚â§‚ÄØ400 tokens**, whichever is *smaller*.
2. **Fence markers** ‚Äì **Wrap each section with the exact regex-friendly fences below.** *Do not alter them.*
3. **Atomicity** ‚Äì HLJ preview items must describe *one* clear action/output (e.g., ‚ÄúDesign `POST /users/signup` endpoint‚Äù). Vague entries like ‚ÄúDo stuff‚Äù are forbidden.
4. **Line-number provenance** ‚Äì Include source line/paragraph numbers in `"line_source": "Ln X‚ÄìY"`. If the source span is unclear, use `"line_source": "(unknown)"`.
5. **Fail-loud quota** ‚Äì If you cannot meet any numeric constraint or required field, output the token `!!CONSTRAINT_BROKEN!!` at the end of the relevant section.
6. **Hallucination flag** ‚Äì Any feature or detail *not* found in the raw text must be prefixed with `[EXTRA]`.
7. **Non-functional checklist** ‚Äì Explicitly check for and preserve cues about **performance, security, scalability, usability, compliance/regulation, availability, maintainability** as appropriate.

---

## üîπ Step‚ÄØ1 ‚Äì Summary Generation

Generate a **structured, developer-friendly summary** that respects Rules‚ÄØ1‚Äì7.
*Preserve all functional & non-functional aspects, dates, deadlines, dependencies, regulations, stakeholder priorities, and critical terminology.*

---

## üîπ Step‚ÄØ2 ‚Äì HLJ Structure Planning (JSON Format)

* **Do *not* generate full HLJs yet.**
* Estimate the **total number of atomic HLJ items**.
* If the count exceeds `MAX_CHUNK_SIZE`, split the preview list into sequential **chunks of MAX\_CHUNK\_SIZE items** and assign each chunk a focus.
* For **each HLJ preview item**, produce a JSON object with:

  * `"id"`
  * `"title"` (1-line, atomic)
  * `"domain"`
  * `"subdomain"` (list)
  * `"tags"` (max 3, canonical, lowercase)
  * `"difficulty"` ("low" | "medium" | "high")
  * `"priority"` ("low" | "medium" | "high")
  * `"line_source"` (e.g., "Ln 10‚Äì13")
  * (Optional: `"chunk"` and `"chunk_focus"` for easier grouping)

*Assign IDs using this pattern: `REQ-025-HLJ-Chunk_<chunk#>-Item_<item#>-v1.0`.*

---

## ‚úÖ  Required Output Format (**fences must stay verbatim**)

### === SUMMARY START ===

{
  "requirement_id": "REQ-025",
  "summary": "<your summary here>"
}

### === SUMMARY END ===

### === HLJ\_META START ===

{
  "domain": "<Domain>",                 // e.g., "FinTech"
  "subdomain": ["<Subdomain1>", ...],   // e.g., ["CustomerOnboarding"]
  "canonical_tags": ["tag1", "tag2"],   // up to 3 tags
  "difficulty": "<low|medium|high>",
  "priority": "<low|medium|high>"
}

### === HLJ\_META END ===

### === HLJ\_PLAN START ===

{
  "estimated_hlj_count": <integer>,
  "chunk_count": <integer>,
  "chunks": [
    {
      "chunk_id": "REQ-025-HLJ-Chunk_<chunk#>",
      "focus": "<focus string or 'unknown'>",
      "items": [
        {
          "id": "REQ-025-HLJ-Chunk_<chunk#>-Item_<item#>-v1.0",
          "title": "<atomic 1-line title>",
          "domain": "<Domain>",
          "subdomain": ["<Subdomain1>", ...],
          "tags": ["tag1", "tag2"],
          "difficulty": "<low|medium|high>",
          "priority": "<low|medium|high>",
          "line_source": "Ln XX‚ÄìYY"
        }
        // ... more items for this chunk
      ]
    }
    // ... more chunks as needed
  ]
}

### === HLJ\_PLAN END ===

*If any rule is violated or information is missing ‚áí append `!!CONSTRAINT_BROKEN!!` on a new line.*

---

## üî∏  Input Placeholder

```
# Requirement req-025 (SaaS)

SA-010: Widget-Level Performance Analytics in User Dashboards
Title:
End-to-End Widget Performance Analytics and Insights for Enhanced User Dashboard Experience

Executive Summary:
Delivering a high-performance, data-driven dashboard experience is essential for retaining power users and meeting enterprise SLAs. We require granular, real-time visibility into the load and render times of individual dashboard widgets, empowering engineering teams to proactively optimize performance and product managers to monitor UX KPIs.

Requirements:

Instrumentation:

Instrument all dashboard widgets (first- and third-party) to capture load, render, and interactive readiness times.

Report timing data per widget instance, user, device, and browser context.

Visualization & Reporting:

Provide engineering dashboards with breakdowns by widget, user segment, and time window.

Flag outliers and regressions, with drill-down to root cause (e.g., CDN lag, third-party script).

Automated Alerting & Optimization:

Trigger alerts for widgets breaching performance SLAs (e.g., >2s load time for 95th percentile).

Integrate with CI/CD to block deployment of code that causes performance regressions, and suggest automated remediation steps.

Edge Cases & Resilience:

For widgets loading from external services, monitor fallback performance and alert on persistent issues.

If user dashboard exceeds performance budget, prompt user to hide or reprioritize widgets.

Compliance & Privacy:

All telemetry data must be anonymized and comply with user privacy agreements.

Offer users transparency into what performance data is collected and allow opt-out.

Documentation & Self-Service:

Provide self-service analytics for product owners to monitor widget health.

Update internal wiki with best practices and troubleshooting guides.

Dependencies & Constraints:

Requires upgrade of telemetry and analytics infrastructure.

Performance monitoring must not degrade dashboard responsiveness.

KPIs:

99% of dashboards load in under 2.5s

<0.5% widget-level error rate

Weekly performance regression resolved within 48 hours
```

**Respond only with text enclosed by the fences above. Do not include any extra commentary or explanation. If information is missing or ambiguous, use `"unknown"` for the value.**
